# Licensed under the MIT license.
import json
import math
from functools import partial
from typing import List, Dict, Any, Optional
import pymongo
from bson import ObjectId

from pikerag.knowledge_retrievers.base_qa_retriever import BaseQaRetriever
from pikerag.utils.config_loader import load_callable
from pikerag.utils.logger import Logger
from pikerag.workflows.common import BaseQaData
from vectorapi.embeddings import get_embeddings_aliyun, get_embedding
from vectorapi.milvus import search_similar_content
from pikerag.knowledge_retrievers.search_internet_baidu import baidu_search, resolve_baidu_url, extract_web_content

def get_messages_info(message, collection_name, limit=30, threshold=None, embedding_func=get_embedding):
    # è·å–messageçš„å‘é‡è¡¨ç¤º
    vectors = embedding_func(message)
    results = search_similar_content(collection_name, [vectors], limit)
    result = []

    # å¤„ç†æœç´¢ç»“æœ
    for query_res in results:
        for hit in query_res:
            # è·å–ç»“æœçš„IDå’Œè·ç¦»
            entity_id = hit.id
            distance = hit.distance

            # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆå‡è®¾ä½¿ç”¨cosineè·ç¦»ï¼‰
            similarity = 1 - distance
            
            # å¦‚æœè®¾ç½®äº†é˜ˆå€¼ï¼Œåˆ™åªè¿”å›ç›¸ä¼¼åº¦å¤§äºé˜ˆå€¼çš„ç»“æœ
            if threshold is not None and similarity < threshold:
                print(f"ğŸ” è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ: {similarity:.3f} < {threshold}")
                continue

            # è·å–å…¶ä»–å­—æ®µçš„å€¼
            field1_value = hit.entity.get('content')
            result.append((entity_id, distance, field1_value))
        
    if len(result) == 0:
        print("âš ï¸ retrieveæ²¡æœ‰ç»“æœï¼Œå¯åŠ¨è”ç½‘æœç´¢")
        # è°ƒç”¨è”ç½‘æœç´¢
        internet_results = baidu_search(message, max_results=3)
        for item in internet_results:
            print(f"ğŸ“Œ æœç´¢åˆ°: {item['title']}")
                
            # è§£æçœŸå®URLå¹¶æå–ç½‘é¡µå†…å®¹
            real_url = resolve_baidu_url(item["url"])
            web_content = extract_web_content(real_url)
                
            if web_content:
                content_text = f"æ ‡é¢˜ï¼š{item['title']}\né“¾æ¥ï¼š{real_url}\nå†…å®¹ï¼š{web_content}"
                print(f"âœ… æˆåŠŸæå–å†…å®¹ï¼Œé•¿åº¦: {len(web_content)}")
            else:
                content_text = f"æ ‡é¢˜ï¼š{item['title']}\né“¾æ¥ï¼š{real_url}\nå†…å®¹ï¼šæ— æ³•æå–ç½‘é¡µå†…å®¹"
                print(f"âŒ å†…å®¹æå–å¤±è´¥")
                
            # å°†è”ç½‘æœç´¢ç»“æœæ·»åŠ åˆ°resultä¸­
            # ä½¿ç”¨è´Ÿæ•°IDæ¥æ ‡è¯†è”ç½‘æœç´¢ç»“æœï¼Œè·ç¦»è®¾ä¸º0è¡¨ç¤ºæœ€ç›¸å…³
            result.append((-len(result)-1, 0.0, content_text))

    return result

class MongoDBMixin:
    """MongoDBè¿æ¥å’Œæ“ä½œçš„æ··å…¥ç±»"""
    
    def create_mongo_uri(
        self,
        host: str = "localhost",
        port: int = 27017,
        username: str = None,
        password: str = None,
        auth_db: str = "admin"
    ) -> str:
        """åˆ›å»ºMongoDBè¿æ¥URI
        
        Args:
            host: MongoDBä¸»æœºåœ°å€
            port: MongoDBç«¯å£
            username: ç”¨æˆ·å
            password: å¯†ç 
            auth_db: è®¤è¯æ•°æ®åº“å
            
        Returns:
            str: MongoDBè¿æ¥URI
        """
        if username and password:
            return f"mongodb://{username}:{password}@{host}:{port}/?authSource={auth_db}"
        return f"mongodb://{host}:{port}/"
        
    def _init_mongodb_mixin(self) -> None:
        """åˆå§‹åŒ–MongoDBè¿æ¥é…ç½®"""
        mongo_config = self._retriever_config.get("mongodb_setting", {})
        self.mongo_uri = self.create_mongo_uri(
            host=mongo_config.get("host", "localhost"),
            port=mongo_config.get("port", 27017),
            username=mongo_config.get("username"),
            password=mongo_config.get("password"),
            auth_db=mongo_config.get("auth_db", "admin")
        )
        self.db_name = mongo_config.get("db_name", "documents")
        self.client = None
        self._main_logger.info(
            msg=f"Initialized MongoDB connection with URI: {self.mongo_uri}",
            tag=self.name
        )
        
    def _get_db(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if not self.client:
            self.client = pymongo.MongoClient(self.mongo_uri)
            self._main_logger.debug(
                msg="Created new MongoDB client connection",
                tag=self.name
            )
        return self.client[self.db_name]
        
    def _close_db(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.client:
            self.client.close()
            self.client = None
            self._main_logger.debug(
                msg="Closed MongoDB client connection",
                tag=self.name
            )


class QaMongoDBRetriever(BaseQaRetriever, MongoDBMixin):
    """åŸºäºMongoDBçš„æ–‡æ¡£æ£€ç´¢å™¨å®ç°"""
    
    name: str = "QaMongoDBRetriever"
    
    def __init__(self, retriever_config: dict, log_dir: str, main_logger: Logger) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨
        
        Args:
            retriever_config: æ£€ç´¢å™¨é…ç½®
            log_dir: æ—¥å¿—ç›®å½•
            main_logger: ä¸»æ—¥å¿—è®°å½•å™¨
        """
        super().__init__(retriever_config, log_dir, main_logger)
        
        # åˆå§‹åŒ–æ£€ç´¢å‚æ•°
        self.retrieve_k = retriever_config.get("retrieve_k", 5)
        self.retrieve_score_threshold = retriever_config.get("retrieve_score_threshold", 1)
        self.embedding_func = eval(retriever_config.get("embedding_func", get_embedding))
        
        self._init_query_parser()
        self._init_mongodb_mixin()
        
    def _init_query_parser(self) -> None:
        """åˆå§‹åŒ–æŸ¥è¯¢è§£æå™¨"""
        query_parser_config: dict = self._retriever_config.get("retrieval_query", None)
        
        if query_parser_config is None:
            self._main_logger.info(
                msg="`retrieval_query` not configured, using default embedding function",
                tag=self.name,
            )
            return
        else:
            parser_func = load_callable(
                module_path=query_parser_config["module_path"],
                name=query_parser_config["func_name"],
            )
            self._query_parser = partial(parser_func, **query_parser_config.get("args", {}))
    
    def _get_document_info(self, doc_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æ–‡æ¡£ä¿¡æ¯"""
        db = self._get_db()
        doc = db.documents.find_one({"_id": ObjectId(doc_id)})
        if doc:
            self._main_logger.debug(
                msg=f"Retrieved document info for doc_id: {doc_id}",
                tag=self.name
            )
        else:
            self._main_logger.warning(
                msg=f"Document not found for doc_id: {doc_id}",
                tag=self.name
            )
        return doc
    
    def _get_node_content(self, node_id: str) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹å†…å®¹"""
        db = self._get_db()
        node = db.document_nodes.find_one({"_id": node_id})
        if node:
            self._main_logger.debug(
                msg=f"Retrieved node content for node_id: {node_id}",
                tag=self.name
            )
        else:
            self._main_logger.warning(
                msg=f"Node not found for node_id: {node_id}",
                tag=self.name
            )
        return node
    
    def _get_siblings(self, parent_id: str, doc_id: str) -> List[Dict[str, Any]]:
        """è·å–åŒçº§èŠ‚ç‚¹"""
        db = self._get_db()
        siblings = list(db.document_nodes.find({
            "parent_id": parent_id,
            "doc_id": doc_id
        }).sort("_id", 1))
        self._main_logger.debug(
            msg=f"Retrieved {len(siblings)} siblings for parent_id: {parent_id}, doc_id: {doc_id}",
            tag=self.name
        )
        return siblings
            
    def retrieve_contents_by_query(self, query: str, retrieve_id: str = "") -> List[str]:
        """æ£€ç´¢æ–‡æ¡£å†…å®¹"""
        retrieve_k = self.retrieve_k
        threshold = self.retrieve_score_threshold

        self._main_logger.info(
            msg=f"Starting content retrieval for query: {query}",
            tag=self.name
        )
        
        # ä»å‘é‡åº“è·å–ç›¸ä¼¼å†…å®¹çš„å‘é‡ID
        vector_results = get_messages_info(
            query, 
            "rag_collection2", 
            limit=retrieve_k,
            threshold=threshold,
            embedding_func=self.embedding_func
        )
        
        self._main_logger.debug(
            msg=f"Vector search returned {len(vector_results)} results: {json.dumps(vector_results, ensure_ascii=False)}",
            tag=self.name
        )
            
        try:
            db = self._get_db()
            results = []
            seen_parent_ids = set()

            for vector_result in vector_results:
                vector_id = vector_result[0]
                distance = vector_result[1]
                content = vector_result[2]
                
                self._main_logger.debug(
                    msg=f"Processing vector_id: {vector_id}, distance: {distance}, content: {content}",
                    tag=self.name
                )
                
                # å¤„ç†è”ç½‘æœç´¢ç»“æœï¼ˆè´Ÿæ•°IDï¼‰
                if vector_id < 0:
                    self._main_logger.info(
                        msg=f"Processing internet search result with ID: {vector_id}",
                        tag=self.name
                    )
                    
                    # è§£æè”ç½‘æœç´¢å†…å®¹ï¼ˆæ ¼å¼ï¼šæ ‡é¢˜ï¼šxxx\né“¾æ¥ï¼šxxx\nå†…å®¹ï¼šxxxï¼‰
                    lines = content.split('\n')
                    title = ""
                    link = ""
                    web_content = ""
                    
                    for line in lines:
                        if line.startswith("æ ‡é¢˜ï¼š"):
                            title = line.replace("æ ‡é¢˜ï¼š", "").strip()
                        elif line.startswith("é“¾æ¥ï¼š"):
                            link = line.replace("é“¾æ¥ï¼š", "").strip()
                        elif line.startswith("å†…å®¹ï¼š"):
                            web_content = line.replace("å†…å®¹ï¼š", "").strip()
                    
                    # æ„é€ è”ç½‘æœç´¢ç»“æœ
                    internet_content = {
                        "æ–‡æ¡£å": "äº’è”ç½‘æœç´¢ç»“æœ",
                        "æ ‡é¢˜": title,
                        "doc_name": link,
                        "å†…å®¹": web_content
                    }
                    results.append(str(internet_content))
                    continue
                
                # å¤„ç†æœ¬åœ°æ•°æ®åº“ç»“æœ
                node = db.document_nodes.find_one({"vector_id": vector_id})
                if not node:
                    self._main_logger.warning(
                        msg=f"Node not found for vector_id: {vector_id}, content from vector store: {content}",
                        tag=self.name
                    )
                    continue
                
                if node["parent_id"] and node["parent_id"] in seen_parent_ids:
                    self._main_logger.debug(
                        msg=f"Skipping duplicate parent_id: {node['parent_id']}",
                        tag=self.name
                    )
                    continue
                
                if node["parent_id"]:
                    seen_parent_ids.add(node["parent_id"])
                
                # å¦‚æœèŠ‚ç‚¹ç±»å‹ä¸ºsentenceï¼Œåˆ™è·å–åŒçº§èŠ‚ç‚¹ã€çˆ¶èŠ‚ç‚¹å’Œæ–‡æ¡£ä¿¡æ¯
                if node["type"] == "sentence":
                    # è·å–åŒçº§èŠ‚ç‚¹
                    siblings = self._get_siblings(node["parent_id"], node["doc_id"])

                    # è·å–çˆ¶èŠ‚ç‚¹
                    parent = None
                    if node["parent_id"]:
                        parent = self._get_node_content(node["parent_id"])
                    
                    # è·å–æ–‡æ¡£ä¿¡æ¯
                    doc = self._get_document_info(node["doc_id"])
                    
                    # ç»„ç»‡å†…å®¹
                    content = {
                        "doc_id": node["doc_id"],
                        "doc_name": doc["name"] if doc else None,
                        "matched_content": node["content"],
                        "node_type": node["type"],
                        "level": node["level"],
                        "siblings": [sib["content"] for sib in siblings],
                        "parent": parent["content"] if parent else None
                    }
                #chapterèŠ‚ç‚¹  
                elif node["type"] == "chapter":
                    # è·å–æ–‡æ¡£ä¿¡æ¯
                    doc = self._get_document_info(node["doc_id"])
                    
                    # è·å–å½“å‰chapterçš„å­èŠ‚ç‚¹ï¼ˆparagraphsï¼‰
                    paragraphs = self._get_siblings(node["_id"], node["doc_id"])
                    # è·å–æ¯ä¸ªparagraphä¸‹çš„æ‰€æœ‰sentence
                    all_sentences = []
                    for para in paragraphs:
                        sentences = self._get_siblings(para["_id"], node["doc_id"])
                        all_sentences.extend([sent["content"] for sent in sentences])
                    if all_sentences:
                        content = {
                            "doc_id": node["doc_id"],
                            "doc_name": doc["name"] if doc else None,
                            "matched_content": node["content"],
                            "node_type": node["type"],
                            "level": node["level"],
                            "sentences": all_sentences
                        }
                # ésentenceå’ŒchapterèŠ‚ç‚¹
                else:
                    # è·å–æ–‡æ¡£ä¿¡æ¯
                    doc = self._get_document_info(node["doc_id"])

                    content = {
                        "doc_id": node["doc_id"],
                        "doc_name": doc["name"] if doc else None,
                        "matched_content": node["content"],
                        "node_type": node["type"],
                        "level": node["level"]
                    }
                
                results.append(str(content))
            
            if len(results) > 0:
                self._main_logger.info(
                    msg=f"Successfully retrieved {len(results)} documents for query",
                    tag=self.name
                )
            else:
                self._main_logger.warning(
                    msg="No documents were retrieved after processing vector results",
                    tag=self.name
                )
                
            return results
            
        except Exception as e:
            self._main_logger.error(
                msg=f"Error during content retrieval: {str(e)}",
                tag=self.name
            )
            raise
        finally:
            self._close_db()


def create_mongo_uri(
    host: str = "localhost",
    port: int = 27017,
    username: str = None,
    password: str = None,
    auth_db: str = "admin"
) -> str:
    """åˆ›å»ºMongoDBè¿æ¥URIçš„ç‹¬ç«‹å‡½æ•°
    
    Args:
        host: MongoDBä¸»æœºåœ°å€
        port: MongoDBç«¯å£
        username: ç”¨æˆ·å
        password: å¯†ç 
        auth_db: è®¤è¯æ•°æ®åº“å
        
    Returns:
        str: MongoDBè¿æ¥URI
    """
    if username and password:
        return f"mongodb://{username}:{password}@{host}:{port}/?authSource={auth_db}"
    return f"mongodb://{host}:{port}/" 